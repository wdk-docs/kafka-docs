# 用例

以下是ApacheKafka®的一些常用用例的描述。
有关这些领域的概述，请参阅此博客文章。

## 消息

Kafka可以替代更传统的消息代理。
消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。
与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能，这使其成为大规模消息处理应用程序的理想解决方案。

根据我们的经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。

在这个领域，Kafka可与传统的消息传递系统（如ActiveMQ或RabbitMQ）相媲美。

## 网站活动跟踪

Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。
这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。
这些源可用于订购一系列用例，包括实时处理，实时监控以及加载到Hadoop或离线数据仓库系统以进行脱机处理和报告。

活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。

## 度量

Kafka通常用于运营监控数据。
这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。

## 日志聚合

许多人使用Kafka作为日志聚合解决方案的替代品。
日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理。
Kafka抽象出文件的细节，并将日志或事件数据作为消息流更清晰地抽象出来。
这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。
与Scribe或Flume等以日志为中心的系统相比，Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。

## 流处理

许多Kafka用户在处理由多个阶段组成的管道时处理数据，其中原始输入数据从Kafka主题中消费，然后聚合，丰富或以其他方式转换为新主题以供进一步消费或后续处理。
例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题;进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题;最终处理阶段可能会尝试向用户推荐此内容。
此类处理管道基于各个主题创建实时数据流的图形。
从0.10.0.0开始，Apache Kafka中提供了一个名为Kafka Streams的轻量级但功能强大的流处理库，用于执行上述数据处理。
除了Kafka Streams之外，其他开源流处理工具包括Apache Storm和Apache Samza。

## 活动采购

事件源是一种应用程序设计风格，其中状态更改记录为按时间排序的记录序列。
Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。

## 提交日志

Kafka可以作为分布式系统的一种外部提交日志。
该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。
Kafka中的日志压缩功能有助于支持此用法。
在这种用法中，Kafka类似于Apache BookKeeper项目。